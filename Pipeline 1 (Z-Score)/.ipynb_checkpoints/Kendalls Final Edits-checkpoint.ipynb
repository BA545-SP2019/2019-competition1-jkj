{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edits for final notebook - Pipeline 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Correlation \n",
    "\n",
    "For our first attempt we performed a filtered feature selection using a spearman correlation. We created a heatmap matrix of correlation score between the features and the label. We then checked if the features are highly correlated with are target variables Y1 and Y2 using the thresholds (>.5 or <-.5). The features are then selected on the basis of their scores. \n",
    "\n",
    "This method did not produce a feasible outcome for feature selection for this data. The only conclusive information we obtained from this method was that C6’ was too correlated with target variable Y1 because it essentially is derived from the same source as Y1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next method for feature selection that we used is Recursive feature elimination (RFE).  This method fits an entire model and then removes the weakest feature/features until the specified number of features is reached. The predictors are ranked by its importance to the model. \n",
    "\n",
    "When we ran the RFE, we recorded the rankings for all the variables and ran the evaluation code for each of the feature selection. \n",
    "\n",
    "For Y1 we’ve come to the conclusion that the best 6 variables produce the best F1 and AUC score. For Y2 our best F1 and AUC score was produced by binning variables prior to running the RFE and using the best 5 variables in our evaluation code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier \n",
    "\n",
    "We also ran an extra trees classifier to report feature importance. The idea is whatever features passing the threshold would be selected and display the relative importance of each attribute. The features selected with the highest relative importance from this method gave us lower F1 scores and AUC, therefore we did not use this method in our final evaluation code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
